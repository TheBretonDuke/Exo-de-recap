{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b2d14a",
   "metadata": {},
   "source": [
    "# 🏭 PARTIE 3 : ETL (EXTRACT, TRANSFORM, LOAD)\n",
    "\n",
    "### 🌟 Ce que vous allez apprendre :\n",
    "- **Extract** : Lire des fichiers CSV et JSON\n",
    "- **Transform** : Nettoyer et enrichir les données\n",
    "- **Load** : Sauvegarder vers différents formats\n",
    "- **Pipeline** : Automatiser le processus complet\n",
    "\n",
    "### 🛠️ Prérequis :\n",
    "Exécutez d'abord la cellule système ci-dessous.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf383928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Installation des packages pour ETL...\n",
      "Cela peut prendre quelques minutes...\n",
      "Requirement already satisfied: pandas>=1.5.0 in ./.venvexoultime/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venvexoultime/lib/python3.12/site-packages (from pandas>=1.5.0) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venvexoultime/lib/python3.12/site-packages (from pandas>=1.5.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venvexoultime/lib/python3.12/site-packages (from pandas>=1.5.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venvexoultime/lib/python3.12/site-packages (from pandas>=1.5.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venvexoultime/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pandas>=1.5.0 installé avec succès\n",
      "Requirement already satisfied: numpy>=1.20.0 in ./.venvexoultime/lib/python3.12/site-packages (2.3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ numpy>=1.20.0 installé avec succès\n",
      "Requirement already satisfied: ipywidgets>=7.6.0 in ./.venvexoultime/lib/python3.12/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venvexoultime/lib/python3.12/site-packages (from ipywidgets>=7.6.0) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venvexoultime/lib/python3.12/site-packages (from ipywidgets>=7.6.0) (9.6.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venvexoultime/lib/python3.12/site-packages (from ipywidgets>=7.6.0) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.venvexoultime/lib/python3.12/site-packages (from ipywidgets>=7.6.0) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venvexoultime/lib/python3.12/site-packages (from ipywidgets>=7.6.0) (3.0.15)\n",
      "Requirement already satisfied: decorator in ./.venvexoultime/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venvexoultime/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venvexoultime/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venvexoultime/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venvexoultime/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venvexoultime/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venvexoultime/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./.venvexoultime/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venvexoultime/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=7.6.0) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venvexoultime/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.6.0) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venvexoultime/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.6.0) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venvexoultime/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.6.0) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venvexoultime/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.6.0) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venvexoultime/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=7.6.0) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ipywidgets>=7.6.0 installé avec succès\n",
      "Requirement already satisfied: requests>=2.28.0 in ./.venvexoultime/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venvexoultime/lib/python3.12/site-packages (from requests>=2.28.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venvexoultime/lib/python3.12/site-packages (from requests>=2.28.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venvexoultime/lib/python3.12/site-packages (from requests>=2.28.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venvexoultime/lib/python3.12/site-packages (from requests>=2.28.0) (2025.10.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ requests>=2.28.0 installé avec succès\n",
      "Requirement already satisfied: openpyxl>=3.0.0 in ./.venvexoultime/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in ./.venvexoultime/lib/python3.12/site-packages (from openpyxl>=3.0.0) (2.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ openpyxl>=3.0.0 installé avec succès\n",
      "Requirement already satisfied: xlsxwriter>=3.0.0 in ./.venvexoultime/lib/python3.12/site-packages (3.2.9)\n",
      "✅ xlsxwriter>=3.0.0 installé avec succès\n",
      "\n",
      "✨ Installation terminée ! Vous pouvez maintenant exécuter les cellules suivantes.\n",
      "📝 Note: Redémarrez le kernel si nécessaire après l'installation.\n",
      "✅ xlsxwriter>=3.0.0 installé avec succès\n",
      "\n",
      "✨ Installation terminée ! Vous pouvez maintenant exécuter les cellules suivantes.\n",
      "📝 Note: Redémarrez le kernel si nécessaire après l'installation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 📦 INSTALLATION DES PACKAGES NÉCESSAIRES\n",
    "# Exécutez cette cellule en premier pour installer tous les packages requis\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Installe un package Python via pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✅ {package} installé avec succès\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"❌ Erreur lors de l'installation de {package}\")\n",
    "\n",
    "# Liste des packages nécessaires pour ce notebook\n",
    "packages = [\n",
    "    \"pandas>=1.5.0\",\n",
    "    \"numpy>=1.20.0\", \n",
    "    \"ipywidgets>=7.6.0\",\n",
    "    \"requests>=2.28.0\",\n",
    "    \"openpyxl>=3.0.0\",\n",
    "    \"xlsxwriter>=3.0.0\"\n",
    "]\n",
    "\n",
    "print(\"🚀 Installation des packages pour ETL...\")\n",
    "print(\"Cela peut prendre quelques minutes...\")\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n✨ Installation terminée ! Vous pouvez maintenant exécuter les cellules suivantes.\")\n",
    "print(\"📝 Note: Redémarrez le kernel si nécessaire après l'installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe69f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏭 Système d'aide ETL chargé !\n",
      "📁 Dossier data_etl créé avec fichiers d'exemple\n",
      "✨ Prêt pour Extract, Transform, Load !\n"
     ]
    }
   ],
   "source": [
    "# 🔧 SYSTÈME D'AIDE ETL (Exécuter une fois)\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import HTML, display\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "class ETLHelper:\n",
    "    def __init__(self):\n",
    "        self.success_style = \"\"\"\n",
    "        <div style=\"background: linear-gradient(90deg, #FF6B35, #F7931E); color: white; padding: 15px; border-radius: 10px; margin: 10px 0; text-align: center; font-weight: bold; font-size: 16px;\">\n",
    "            🏭 {message} 🏭\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(\"data_etl\")\n",
    "        self.data_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Base de données des aides cachées\n",
    "        self.helps = {\n",
    "            \"3.1.1\": {\n",
    "                \"hint\": \"Utilisez pd.read_csv('chemin/fichier.csv'). Le fichier sera dans le dossier data_etl/\",\n",
    "                \"solution\": \"\"\"# Extract - Lire le fichier CSV des ventes\n",
    "df_ventes = pd.read_csv('data_etl/ventes.csv')\n",
    "\n",
    "print(f\"📊 Ventes extraites: {len(df_ventes)} lignes\")\n",
    "print(\"📋 Colonnes:\", list(df_ventes.columns))\n",
    "print(\"\\\\n🔍 Aperçu:\")\n",
    "print(df_ventes.head())\"\"\",\n",
    "                \"explanation\": \"pd.read_csv() lit un fichier CSV et le convertit en DataFrame. Vérifiez toujours la structure après extraction.\"\n",
    "            },\n",
    "            \"3.1.2\": {\n",
    "                \"hint\": \"Utilisez pd.read_json('chemin/fichier.json'). Les données JSON peuvent avoir une structure complexe.\",\n",
    "                \"solution\": \"\"\"# Extract - Lire le fichier JSON des clients  \n",
    "df_clients = pd.read_json('data_etl/clients.json')\n",
    "\n",
    "print(f\"👥 Clients extraits: {len(df_clients)} lignes\") \n",
    "print(\"📋 Colonnes:\", list(df_clients.columns))\n",
    "print(\"\\\\n🔍 Aperçu:\")\n",
    "print(df_clients.head())\"\"\",\n",
    "                \"explanation\": \"pd.read_json() convertit les données JSON en DataFrame. JSON peut contenir des structures imbriquées.\"\n",
    "            },\n",
    "            \"3.2.1\": {\n",
    "                \"hint\": \"Utilisez .dropna(), .fillna(), .astype() pour nettoyer. pd.to_datetime() pour les dates.\",\n",
    "                \"solution\": \"\"\"# Transform - Nettoyer les données de ventes\n",
    "df_ventes_clean = df_ventes.copy()\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes critiques\n",
    "df_ventes_clean = df_ventes_clean.dropna(subset=['produit', 'prix'])\n",
    "\n",
    "# Convertir les dates\n",
    "df_ventes_clean['date'] = pd.to_datetime(df_ventes_clean['date'])\n",
    "\n",
    "# Nettoyer les prix (convertir en float)\n",
    "df_ventes_clean['prix'] = pd.to_numeric(df_ventes_clean['prix'], errors='coerce')\n",
    "\n",
    "# Supprimer les prix invalides\n",
    "df_ventes_clean = df_ventes_clean.dropna(subset=['prix'])\n",
    "\n",
    "print(f\"🧹 Données nettoyées: {len(df_ventes_clean)} lignes (était {len(df_ventes)})\")\"\"\",\n",
    "                \"explanation\": \"Transform nettoie et transforme les données: suppression des nulls, conversion de types, validation.\"\n",
    "            },\n",
    "            \"3.2.2\": {\n",
    "                \"hint\": \"Utilisez les mêmes techniques de nettoyage. Attention aux données clients qui peuvent être plus complexes.\",\n",
    "                \"solution\": \"\"\"# Transform - Nettoyer les données clients\n",
    "df_clients_clean = df_clients.copy()\n",
    "\n",
    "# Supprimer les doublons basés sur l'email\n",
    "df_clients_clean = df_clients_clean.drop_duplicates(subset=['email'], keep='first')\n",
    "\n",
    "# Nettoyer les âges (valeurs raisonnables)\n",
    "df_clients_clean = df_clients_clean[(df_clients_clean['age'] >= 18) & (df_clients_clean['age'] <= 100)]\n",
    "\n",
    "# Nettoyer les noms (pas de valeurs vides)\n",
    "df_clients_clean = df_clients_clean.dropna(subset=['nom', 'email'])\n",
    "\n",
    "print(f\"👥 Clients nettoyés: {len(df_clients_clean)} lignes (était {len(df_clients)})\")\"\"\",\n",
    "                \"explanation\": \"Nettoyage spécifique aux clients: suppression doublons, validation âges, données obligatoires.\"\n",
    "            },\n",
    "            \"3.3.2\": {\n",
    "                \"hint\": \"Utilisez .to_json() avec les paramètres orient et indent pour un JSON lisible.\",\n",
    "                \"solution\": \"\"\"# Load - Sauvegarder en JSON\n",
    "# Fusion des données pour créer un dataset complet\n",
    "df_final = df_ventes_clean.merge(df_clients_clean, left_on='client_id', right_on='id', how='inner')\n",
    "\n",
    "# Sauvegarder en JSON avec formatage\n",
    "output_json = 'data_etl/rapport_final.json'\n",
    "df_final.to_json(output_json, orient='records', indent=2, date_format='iso')\n",
    "\n",
    "print(f\"💾 Données sauvegardées en JSON: {output_json}\")\n",
    "print(f\"📊 {len(df_final)} enregistrements dans le fichier final\")\"\"\",\n",
    "                \"explanation\": \"to_json() sauvegarde un DataFrame en JSON. orient='records' crée un format liste de dictionnaires.\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def help(self, step):\n",
    "        \"\"\"Affiche l'aide pour une étape donnée\"\"\"\n",
    "        if step not in self.helps:\n",
    "            print(f\"❌ Aide non trouvée pour l'étape {step}\")\n",
    "            return\n",
    "            \n",
    "        help_data = self.helps[step]\n",
    "        \n",
    "        # Conseil caché\n",
    "        html_hint = f\"\"\"\n",
    "        <details style=\"margin: 10px 0; border: 1px solid #ddd; border-radius: 5px; padding: 5px; background: #f9f9f9;\">\n",
    "            <summary style=\"cursor: pointer; background: #fff3e0; padding: 10px; border-radius: 3px; font-weight: bold; color: #ef6c00;\">\n",
    "                💡 Conseil ETL (cliquer pour dérouler)\n",
    "            </summary>\n",
    "            <div style=\"padding: 15px; margin-top: 10px; background: white; border-radius: 3px;\">\n",
    "                <p style=\"margin: 0; color: #333;\">{help_data['hint']}</p>\n",
    "            </div>\n",
    "        </details>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Solution cachée\n",
    "        html_solution = f\"\"\"\n",
    "        <details style=\"margin: 10px 0; border: 1px solid #ddd; border-radius: 5px; padding: 5px; background: #f9f9f9;\">\n",
    "            <summary style=\"cursor: pointer; background: #e8f5e8; padding: 10px; border-radius: 3px; font-weight: bold; color: #2e7d32;\">\n",
    "                🔍 Solution ETL (cliquer pour dérouler)\n",
    "            </summary>\n",
    "            <div style=\"padding: 15px; margin-top: 10px; background: white; border-radius: 3px;\">\n",
    "                <p><strong>🏭 Explication :</strong> {help_data['explanation']}</p>\n",
    "                <pre style=\"background: #f5f5f5; padding: 10px; border-radius: 3px; overflow-x: auto; border-left: 3px solid #ff6b35;\"><code>{help_data['solution']}</code></pre>\n",
    "            </div>\n",
    "        </details>\n",
    "        \"\"\"\n",
    "        \n",
    "        display(HTML(html_hint))\n",
    "        display(HTML(html_solution))\n",
    "    \n",
    "    def solution(self, code, explanation=\"\"):\n",
    "        html = f\"\"\"\n",
    "        <details style=\"margin: 10px 0; border: 1px solid #ddd; border-radius: 5px; padding: 5px;\">\n",
    "            <summary style=\"cursor: pointer; background: #fff3e0; padding: 10px; border-radius: 3px; font-weight: bold;\">\n",
    "                🔍 Solution ETL (cliquer pour révéler)\n",
    "            </summary>\n",
    "            <div style=\"background: #fafafa; padding: 15px; margin-top: 10px; border-radius: 3px;\">\n",
    "                {f'<p><strong>🏭 Explication ETL:</strong> {explanation}</p>' if explanation else ''}\n",
    "                <pre style=\"background: #f8f8f8; padding: 10px; border-radius: 3px; overflow-x: auto;\"><code>{code}</code></pre>\n",
    "            </div>\n",
    "        </details>\n",
    "        \"\"\"\n",
    "        display(HTML(html))\n",
    "    \n",
    "    def hint(self, text):\n",
    "        html = f\"\"\"\n",
    "        <details style=\"margin: 10px 0; border: 1px solid #ddd; border-radius: 5px; padding: 5px;\">\n",
    "            <summary style=\"cursor: pointer; background: #fff3e0; padding: 10px; border-radius: 3px; font-weight: bold;\">\n",
    "                💡 Conseil ETL (cliquer pour révéler)\n",
    "            </summary>\n",
    "            <div style=\"background: #fffdf7; padding: 15px; margin-top: 10px; border-radius: 3px;\">\n",
    "                {text}\n",
    "            </div>\n",
    "        </details>\n",
    "        \"\"\"\n",
    "        display(HTML(html))\n",
    "    \n",
    "    def _check_file_exists(self, filename):\n",
    "        filepath = self.data_dir / filename\n",
    "        return filepath.exists(), str(filepath)\n",
    "    \n",
    "    def _check_dataframe(self, df_name, min_rows=None, required_columns=None):\n",
    "        try:\n",
    "            frame = sys._getframe(2)\n",
    "            df = frame.f_globals.get(df_name, frame.f_locals.get(df_name))\n",
    "            \n",
    "            if df is None:\n",
    "                return False, f\"❌ DataFrame '{df_name}' non trouvé\"\n",
    "            \n",
    "            if not isinstance(df, pd.DataFrame):\n",
    "                return False, f\"❌ '{df_name}' n'est pas un DataFrame pandas\"\n",
    "            \n",
    "            if min_rows and len(df) < min_rows:\n",
    "                return False, f\"❌ DataFrame trop petit: {len(df)} lignes (minimum: {min_rows})\"\n",
    "            \n",
    "            if required_columns:\n",
    "                missing = [col for col in required_columns if col not in df.columns]\n",
    "                if missing:\n",
    "                    return False, f\"❌ Colonnes manquantes: {missing}\"\n",
    "            \n",
    "            info = f\"✅ DataFrame '{df_name}': {df.shape[0]} lignes × {df.shape[1]} colonnes\"\n",
    "            if required_columns:\n",
    "                info += f\"\\n✅ Colonnes requises présentes: {required_columns}\"\n",
    "            \n",
    "            return True, info\n",
    "            \n",
    "        except Exception as e:\n",
    "            return False, f\"❌ Erreur: {e}\"\n",
    "    \n",
    "    def check_extract_button(self, df_name, source_file, min_rows=None):\n",
    "        output = widgets.Output()\n",
    "        button = widgets.Button(\n",
    "            description=f\"📥 Vérifier Extract\",\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='200px', height='35px')\n",
    "        )\n",
    "        \n",
    "        def on_click(b):\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                # Vérifier le fichier source\n",
    "                file_exists, filepath = self._check_file_exists(source_file)\n",
    "                if not file_exists:\n",
    "                    print(f\"❌ Fichier source manquant: {source_file}\")\n",
    "                    return\n",
    "                \n",
    "                # Vérifier le DataFrame\n",
    "                success, message = self._check_dataframe(df_name, min_rows)\n",
    "                if success:\n",
    "                    print(f\"🎉 EXTRACT réussi !\")\n",
    "                    print(message)\n",
    "                    print(f\"📁 Source: {source_file}\")\n",
    "                else:\n",
    "                    print(message)\n",
    "        \n",
    "        button.on_click(on_click)\n",
    "        display(widgets.VBox([button, output]))\n",
    "    \n",
    "    def check_transform_button(self, df_name, required_columns=None, min_rows=None):\n",
    "        output = widgets.Output()\n",
    "        button = widgets.Button(\n",
    "            description=f\"🔄 Vérifier Transform\",\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='220px', height='35px')\n",
    "        )\n",
    "        \n",
    "        def on_click(b):\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                success, message = self._check_dataframe(df_name, min_rows, required_columns)\n",
    "                if success:\n",
    "                    print(f\"🎉 TRANSFORM réussi !\")\n",
    "                    print(message)\n",
    "                else:\n",
    "                    print(message)\n",
    "        \n",
    "        button.on_click(on_click)\n",
    "        display(widgets.VBox([button, output]))\n",
    "    \n",
    "    def check_load_button(self, output_file, df_name=None):\n",
    "        output = widgets.Output()\n",
    "        button = widgets.Button(\n",
    "            description=f\"💾 Vérifier Load\",\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(width='200px', height='35px')\n",
    "        )\n",
    "        \n",
    "        def on_click(b):\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                file_exists, filepath = self._check_file_exists(output_file)\n",
    "                if file_exists:\n",
    "                    file_size = os.path.getsize(filepath)\n",
    "                    print(f\"🎉 LOAD réussi !\")\n",
    "                    print(f\"📁 Fichier créé: {output_file}\")\n",
    "                    print(f\"📊 Taille: {file_size} bytes\")\n",
    "                    \n",
    "                    # Vérifier le DataFrame si fourni\n",
    "                    if df_name:\n",
    "                        success, message = self._check_dataframe(df_name)\n",
    "                        if success:\n",
    "                            print(f\"✅ {message}\")\n",
    "                else:\n",
    "                    print(f\"❌ Fichier non créé: {output_file}\")\n",
    "        \n",
    "        button.on_click(on_click)\n",
    "        display(widgets.VBox([button, output]))\n",
    "    \n",
    "    def success(self, message):\n",
    "        html = self.success_style.format(message=message)\n",
    "        display(HTML(html))\n",
    "    \n",
    "    def create_sample_data(self):\n",
    "        \"\"\"Crée des fichiers de données d'exemple pour les exercices\"\"\"\n",
    "        # CSV des ventes\n",
    "        sales_data = {\n",
    "            'date': [f\"2024-{random.randint(1,12):02d}-{random.randint(1,28):02d}\" for _ in range(100)],\n",
    "            'produit': [random.choice(['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Phone']) for _ in range(100)],\n",
    "            'quantite': [random.randint(1, 10) for _ in range(100)],\n",
    "            'prix_unitaire': [round(random.uniform(10, 1000), 2) for _ in range(100)],\n",
    "            'vendeur': [random.choice(['Alice', 'Bob', 'Charlie', 'Diana', 'Eve']) for _ in range(100)]\n",
    "        }\n",
    "        \n",
    "        sales_df = pd.DataFrame(sales_data)\n",
    "        sales_df.to_csv(self.data_dir / 'ventes.csv', index=False)\n",
    "        \n",
    "        # JSON des clients\n",
    "        clients_data = {\n",
    "            'clients': [\n",
    "                {\n",
    "                    'id': i,\n",
    "                    'nom': random.choice(['Martin', 'Dubois', 'Moreau', 'Laurent', 'Bernard']),\n",
    "                    'prenom': random.choice(['Jean', 'Marie', 'Pierre', 'Sophie', 'Nicolas']),\n",
    "                    'email': f\"client{i}@email.com\",\n",
    "                    'age': random.randint(18, 70),\n",
    "                    'ville': random.choice(['Paris', 'Lyon', 'Marseille', 'Toulouse', 'Nice'])\n",
    "                }\n",
    "                for i in range(1, 51)\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        with open(self.data_dir / 'clients.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(clients_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def demo_button(self, demo_func, button_text=\"🎬 Voir la démonstration\"):\n",
    "        output = widgets.Output()\n",
    "        button = widgets.Button(\n",
    "            description=button_text,\n",
    "            button_style='primary',\n",
    "            layout=widgets.Layout(width='250px', height='35px')\n",
    "        )\n",
    "        \n",
    "        def on_click(b):\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                demo_func()\n",
    "        \n",
    "        button.on_click(on_click)\n",
    "        display(widgets.VBox([button, output]))\n",
    "\n",
    "# Création de l'assistant ETL\n",
    "etl_helper = ETLHelper()\n",
    "\n",
    "# Création des données d'exemple\n",
    "etl_helper.create_sample_data()\n",
    "\n",
    "print(\"🏭 Système d'aide ETL chargé !\")\n",
    "print(\"📁 Dossier data_etl créé avec fichiers d'exemple\")\n",
    "print(\"✨ Prêt pour Extract, Transform, Load !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184947a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🌟 Section 3.1 : EXTRACT - Lecture des Données\n",
    "\n",
    "### 🎯 Objectif :\n",
    "Maîtriser la lecture de différents formats de données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769cc809",
   "metadata": {},
   "source": [
    "### 📝 Étape 3.1.1 : Extraction CSV\n",
    "\n",
    "**Instructions :**\n",
    "Lire le fichier `ventes.csv` avec pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43702db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📝 ÉTAPE 3.1.1 : Lecture CSV\n",
    "# Lisez le fichier 'data_etl/ventes.csv' dans un DataFrame 'df_ventes'\n",
    "# Utilisez pd.read_csv()\n",
    "\n",
    "# Syntaxe : df = pd.read_csv('chemin/fichier.csv')\n",
    "\n",
    "# 👇 Lisez le fichier CSV ici :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19edafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💡 Aide pour l'étape 3.1.1\n",
    "etl_helper.help(\"3.1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9181a",
   "metadata": {},
   "source": [
    "### 📝 Étape 3.1.2 : Extraction JSON\n",
    "\n",
    "**Instructions :**\n",
    "Lire le fichier `clients.json` et le convertir en DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📝 ÉTAPE 3.1.2 : Lecture JSON\n",
    "# 1. Ouvrez le fichier 'data_etl/clients.json' avec json.load()\n",
    "# 2. Convertissez les données JSON en DataFrame 'df_clients'\n",
    "# \n",
    "# Structure JSON :\n",
    "# {\n",
    "#   \"clients\": [\n",
    "#     {\"id\": 1, \"nom\": \"Martin\", ...},\n",
    "#     {\"id\": 2, \"nom\": \"Dubois\", ...}\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# Syntaxe :\n",
    "# with open('fichier.json', 'r', encoding='utf-8') as f:\n",
    "#     data = json.load(f)\n",
    "# df = pd.DataFrame(data['clients'])\n",
    "\n",
    "# 👇 Lisez le fichier JSON ici :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💡 Aide pour l'étape 3.1.2\n",
    "etl_helper.help(\"3.1.2\")\n",
    "\n",
    "etl_helper.success(\"Section 3.1 terminée ! Vous maîtrisez l'extraction de données !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088553f5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🌟 Section 3.2 : TRANSFORM - Transformation des Données\n",
    "\n",
    "### 🎯 Objectif :\n",
    "Nettoyer, enrichir et transformer les données extraites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3668b8c1",
   "metadata": {},
   "source": [
    "### 📝 Étape 3.2.1 : Nettoyage des données ventes\n",
    "\n",
    "**Instructions :**\n",
    "Transformer et enrichir le DataFrame des ventes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e1c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📝 ÉTAPE 3.2.1 : Transform ventes\n",
    "# Transformez df_ventes en df_ventes_clean avec ces opérations :\n",
    "# 1. Convertir la colonne 'date' en datetime avec pd.to_datetime()\n",
    "# 2. Créer une colonne 'montant_total' = quantite * prix_unitaire\n",
    "# 3. Créer une colonne 'mois' extraite de la date (df['date'].dt.month)\n",
    "# 4. Créer une colonne 'categorie_prix' :\n",
    "#    - 'Économique' si prix_unitaire < 50\n",
    "#    - 'Moyen' si 50 <= prix_unitaire < 200  \n",
    "#    - 'Premium' si prix_unitaire >= 200\n",
    "\n",
    "# Commencez par copier le DataFrame original :\n",
    "# df_ventes_clean = df_ventes.copy()\n",
    "\n",
    "# 👇 Transformez les données ici :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎬 Démonstration des transformations\n",
    "def demo_transform_ventes():\n",
    "    try:\n",
    "        print(\"🔄 TRANSFORMATIONS APPLIQUÉES\")\n",
    "        print(\"=\"*35)\n",
    "        print(f\"📊 Nouvelles colonnes: {list(df_ventes_clean.columns)}\")\n",
    "        print(f\"💰 Montant total moyen: {df_ventes_clean['montant_total'].mean():.2f}€\")\n",
    "        print(f\"📅 Type colonne date: {df_ventes_clean['date'].dtype}\")\n",
    "        \n",
    "        print(\"\\n📈 Répartition catégories prix:\")\n",
    "        print(df_ventes_clean['categorie_prix'].value_counts())\n",
    "        \n",
    "        print(\"\\n🔍 Aperçu données transformées:\")\n",
    "        print(df_ventes_clean[['produit', 'prix_unitaire', 'quantite', 'montant_total', 'categorie_prix']].head())\n",
    "        \n",
    "    except NameError:\n",
    "        print(\"⚠️ Créez d'abord df_ventes_clean\")\n",
    "\n",
    "etl_helper.demo_button(demo_transform_ventes, \"🎬 Voir les transformations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💡 Aide pour l'étape 3.2.1\n",
    "etl_helper.help(\"3.2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1c06d",
   "metadata": {},
   "source": [
    "### 📝 Étape 3.2.2 : Enrichissement des données clients\n",
    "\n",
    "**Instructions :**\n",
    "Transformer le DataFrame des clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b63354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📝 ÉTAPE 3.2.2 : Transform clients\n",
    "# Transformez df_clients en df_clients_clean avec :\n",
    "# 1. Créer une colonne 'nom_complet' = prenom + \" \" + nom\n",
    "# 2. Créer une colonne 'tranche_age' :\n",
    "#    - 'Jeune' si age < 30\n",
    "#    - 'Adulte' si 30 <= age < 50\n",
    "#    - 'Senior' si age >= 50\n",
    "# 3. Créer une colonne 'region' selon la ville :\n",
    "#    - 'Nord' pour Paris, Lyon\n",
    "#    - 'Sud' pour Marseille, Nice, Toulouse\n",
    "\n",
    "# 👇 Transformez les clients ici :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffed09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💡 Aide pour l'étape 3.2.2\n",
    "etl_helper.help(\"3.2.2\")\n",
    "\n",
    "etl_helper.success(\"Section 3.2 terminée ! Vous maîtrisez la transformation de données !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994801b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🌟 Section 3.3 : LOAD - Sauvegarde des Données\n",
    "\n",
    "### 🎯 Objectif :\n",
    "Sauvegarder les données transformées vers différents formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db7161",
   "metadata": {},
   "source": [
    "### 📝 Étape 3.3.1 : Sauvegarde CSV\n",
    "\n",
    "**Instructions :**\n",
    "Sauvegarder les DataFrames transformés en CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b45b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📝 ÉTAPE 3.3.1 : Sauvegarde CSV\n",
    "# Sauvegardez les DataFrames transformés :\n",
    "# 1. df_ventes_clean → 'data_etl/ventes_clean.csv'\n",
    "# 2. df_clients_clean → 'data_etl/clients_clean.csv'\n",
    "\n",
    "# Utilisez .to_csv() avec index=False pour éviter les index\n",
    "\n",
    "# 👇 Sauvegardez en CSV ici :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c400cf3",
   "metadata": {},
   "source": [
    "### 📝 Étape 3.3.2 : Agrégation et sauvegarde JSON\n",
    "\n",
    "**Instructions :**\n",
    "Créer un rapport agrégé et le sauvegarder en JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80a5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📝 ÉTAPE 3.3.2 : Rapport agrégé JSON\n",
    "# Créez un dictionnaire 'rapport_ventes' avec :\n",
    "# 1. 'total_ventes' : somme de tous les montants_total\n",
    "# 2. 'nb_transactions' : nombre total de lignes\n",
    "# 3. 'vente_moyenne' : montant moyen par transaction\n",
    "# 4. 'top_produits' : les 3 produits les plus vendus (en quantité)\n",
    "# 5. 'ventes_par_mois' : montant total par mois\n",
    "# 6. 'date_rapport' : date actuelle (datetime.now().isoformat())\n",
    "\n",
    "# Puis sauvegardez en JSON dans 'data_etl/rapport_ventes.json'\n",
    "\n",
    "# Aide :\n",
    "# - .sum(), .mean(), .count() pour les agrégations\n",
    "# - .groupby('produit')['quantite'].sum().nlargest(3) pour le top\n",
    "# - .groupby('mois')['montant_total'].sum() pour par mois\n",
    "\n",
    "# 👇 Créez et sauvegardez le rapport ici :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff991a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💡 Aide pour l'étape 3.3.2\n",
    "etl_helper.help(\"3.3.2\")\n",
    "\n",
    "etl_helper.success(\"Section 3.3 terminée ! Vous maîtrisez la sauvegarde de données !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e533d668",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🌟 Section 3.4 : Pipeline ETL Complet\n",
    "\n",
    "### 🎯 Objectif :\n",
    "Créer une fonction pipeline complète automatisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📝 ÉTAPE 3.4 : Pipeline ETL automatisé\n",
    "# Créez une fonction 'pipeline_etl()' qui :\n",
    "# 1. EXTRACT : lit les fichiers CSV et JSON\n",
    "# 2. TRANSFORM : applique toutes les transformations\n",
    "# 3. LOAD : sauvegarde tous les résultats\n",
    "# 4. Retourne un dictionnaire avec les métriques du pipeline\n",
    "\n",
    "def pipeline_etl():\n",
    "    \"\"\"Pipeline ETL complet automatisé\"\"\"\n",
    "    print(\"🏭 DÉMARRAGE PIPELINE ETL\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # 📥 EXTRACT\n",
    "    print(\"📥 Phase EXTRACT...\")\n",
    "    # Votre code extract ici\n",
    "    \n",
    "    # 🔄 TRANSFORM  \n",
    "    print(\"🔄 Phase TRANSFORM...\")\n",
    "    # Votre code transform ici\n",
    "    \n",
    "    # 💾 LOAD\n",
    "    print(\"💾 Phase LOAD...\")\n",
    "    # Votre code load ici\n",
    "    \n",
    "    # 📊 Métriques\n",
    "    metriques = {\n",
    "        'ventes_lues': 0,  # Remplacez par len(df_ventes)\n",
    "        'clients_lus': 0,  # Remplacez par len(df_clients)\n",
    "        'ventes_transformees': 0,  # len(df_ventes_clean)\n",
    "        'clients_transformes': 0,  # len(df_clients_clean)\n",
    "        'fichiers_crees': 0,  # Nombre de fichiers créés\n",
    "        'duree': 0  # En secondes\n",
    "    }\n",
    "    \n",
    "    print(\"✅ PIPELINE TERMINÉ\")\n",
    "    return metriques\n",
    "\n",
    "# 👇 Complétez la fonction pipeline_etl :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💡 Aide pour le pipeline complet\n",
    "etl_helper.solution(\n",
    "    \"\"\"def pipeline_etl():\n",
    "    \\\"\\\"\\\"Pipeline ETL complet automatisé\\\"\\\"\\\"\n",
    "    start_time = time.time()\n",
    "    print(\"🏭 DÉMARRAGE PIPELINE ETL\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # 📥 EXTRACT\n",
    "    print(\"📥 Phase EXTRACT...\")\n",
    "    df_ventes = pd.read_csv('data_etl/ventes.csv')\n",
    "    with open('data_etl/clients.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    df_clients = pd.DataFrame(data['clients'])\n",
    "    \n",
    "    # 🔄 TRANSFORM  \n",
    "    print(\"🔄 Phase TRANSFORM...\")\n",
    "    df_ventes_clean = df_ventes.copy()\n",
    "    df_ventes_clean['date'] = pd.to_datetime(df_ventes_clean['date'])\n",
    "    df_ventes_clean['montant_total'] = df_ventes_clean['quantite'] * df_ventes_clean['prix_unitaire']\n",
    "    df_ventes_clean['mois'] = df_ventes_clean['date'].dt.month\n",
    "    df_ventes_clean['categorie_prix'] = np.where(\n",
    "        df_ventes_clean['prix_unitaire'] < 50, 'Économique',\n",
    "        np.where(df_ventes_clean['prix_unitaire'] < 200, 'Moyen', 'Premium')\n",
    "    )\n",
    "    \n",
    "    df_clients_clean = df_clients.copy()\n",
    "    df_clients_clean['nom_complet'] = df_clients_clean['prenom'] + \\\" \\\" + df_clients_clean['nom']\n",
    "    df_clients_clean['tranche_age'] = np.where(\n",
    "        df_clients_clean['age'] < 30, 'Jeune',\n",
    "        np.where(df_clients_clean['age'] < 50, 'Adulte', 'Senior')\n",
    "    )\n",
    "    mapping_region = {\n",
    "        'Paris': 'Nord', 'Lyon': 'Nord',\n",
    "        'Marseille': 'Sud', 'Nice': 'Sud', 'Toulouse': 'Sud'\n",
    "    }\n",
    "    df_clients_clean['region'] = df_clients_clean['ville'].map(mapping_region)\n",
    "    \n",
    "    # 💾 LOAD\n",
    "    print(\"💾 Phase LOAD...\")\n",
    "    df_ventes_clean.to_csv('data_etl/ventes_clean.csv', index=False)\n",
    "    df_clients_clean.to_csv('data_etl/clients_clean.csv', index=False)\n",
    "    \n",
    "    rapport_ventes = {\n",
    "        'total_ventes': float(df_ventes_clean['montant_total'].sum()),\n",
    "        'nb_transactions': int(len(df_ventes_clean)),\n",
    "        'vente_moyenne': float(df_ventes_clean['montant_total'].mean()),\n",
    "        'date_rapport': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open('data_etl/rapport_ventes.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(rapport_ventes, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # 📊 Métriques\n",
    "    duree = time.time() - start_time\n",
    "    metriques = {\n",
    "        'ventes_lues': len(df_ventes),\n",
    "        'clients_lus': len(df_clients), \n",
    "        'ventes_transformees': len(df_ventes_clean),\n",
    "        'clients_transformes': len(df_clients_clean),\n",
    "        'fichiers_crees': 3,\n",
    "        'duree': duree\n",
    "    }\n",
    "    \n",
    "    print(\"✅ PIPELINE TERMINÉ\")\n",
    "    return metriques\"\"\",\n",
    "    \"Un pipeline ETL automatise Extract→Transform→Load. Mesurez les performances et gérez les erreurs.\"\n",
    ")\n",
    "\n",
    "etl_helper.success(\"FÉLICITATIONS ! Vous maîtrisez l'ETL complet !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f4767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎉 VALIDATION FINALE ETL\n",
    "etl_helper.success(\"MAÎTRE ETL ! Pipeline automatisé maîtrisé !\")\n",
    "\n",
    "print(\"\\n🏆 COMPÉTENCES ETL ACQUISES :\")\n",
    "print(\"✅ Extract: CSV, JSON, API\")\n",
    "print(\"✅ Transform: Nettoyage, enrichissement, agrégation\")\n",
    "print(\"✅ Load: CSV, JSON, bases de données\")\n",
    "print(\"✅ Pipeline: Automatisation complète\")\n",
    "print(\"✅ Monitoring: Métriques et performance\")\n",
    "print(\"\\n🚀 Prêt pour : SQLite et bases de données !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvexoultime (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
